{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML Exercise: Handwritten Digit Recognition\n",
        "\n",
        "This is a personal exercise to help me understand and practice basic machine learning concepts. The goal is to build a model that can recognize handwritten digits based on the MNIST dataset."
      ],
      "metadata": {
        "id": "PZh9YWl-GDV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "RgEluW0EkvOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Plot some of the 28x28 images in the dataset along with\n",
        "# the corresponding label.\n",
        "def visualize(dataset, labels):\n",
        "  plt.figure(figsize=(6, 2))\n",
        "  for i in range(12):\n",
        "      plt.subplot(3, 4, i + 1)\n",
        "      plt.imshow(dataset[i].reshape(28, 28), cmap='gray')\n",
        "      plt.title(f\"Label: {labels[i]}\")\n",
        "      plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig('sample_digits.png')\n",
        "  plt.show()\n",
        "\n",
        "# A model step which flattens the 2D images into a 1D array of pixel values.\n",
        "reshape = FunctionTransformer(\n",
        "    lambda X: X.reshape(X.shape[0], -1),\n",
        "    validate=False\n",
        ")"
      ],
      "metadata": {
        "id": "dFG2OgqFHJsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjiTt-qNRz3A"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST dataset\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
        "\n",
        "print(\"MNIST dataset loaded.\")\n",
        "print(f\"Dataset has {len(xtrain)} examples of type: {xtrain.dtype}. Dataset shape: {xtrain.shape}\")\n",
        "print(f\"Test data has {len(xtest)} examples of type: {xtest.dtype}. Dataset shape: {xtest.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some samples\n",
        "\n",
        "visualize(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "HEUpH7zOVqYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Classify zeros and ones"
      ],
      "metadata": {
        "id": "1PkvmRE5D-AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (ytrain == 0) | (ytrain == 1)\n",
        "\n",
        "training_data = xtrain[mask]\n",
        "training_labels = ytrain[mask]\n",
        "\n",
        "mask = (ytest == 0) | (ytest == 1)\n",
        "\n",
        "test_data = xtest[mask]\n",
        "test_labels = ytest[mask]\n",
        "\n",
        "print(\"Filtered the original dataset for only zeros and ones.\")\n",
        "print(f\"Dataset has {len(training_data)} examples of type: {training_data.dtype}. Dataset shape: {training_data.shape}\")\n",
        "print(f\"Test data has {len(test_data)} examples of type: {test_data.dtype}. Dataset shape: {test_data.shape}\")"
      ],
      "metadata": {
        "id": "BXFoPV9DDTKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some samples\n",
        "\n",
        "visualize(training_data, training_labels)"
      ],
      "metadata": {
        "id": "vpb85vv0HR2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Attempting a linear regression\n",
        "\n",
        "Linear regression will not understand this as a classification problem of distinguishing between zeros and ones. It outputs floating-point predictions. The output is what the model actually expects the label to be, and NOT some probability of the label being zero or one. That's why some outputs will be outside the [0, 1] range.\n",
        "\n",
        "However, because the training labels were always either 0 or 1, the models predictions don't stray too far off from these values in either direction, and it's reasonable to expect that predictions \"close enough\" to 0 mean the handwritten digit is 0, and predictions \"close enough\" to 1 mean the handwritten digit is 1."
      ],
      "metadata": {
        "id": "givqvc_UfmJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "model = make_pipeline(\n",
        "    # Reshape 2D images into a 1D array of pixel values\n",
        "    reshape,\n",
        "    # Normalize the values to have comparable magnitude for\n",
        "    # better performance and faster convergence\n",
        "    StandardScaler(),\n",
        "    # Run training through linear regression\n",
        "    LinearRegression())\n",
        "\n",
        "# Run the training\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "print(predictions)\n",
        "print(test_labels)"
      ],
      "metadata": {
        "id": "lyrNUqpWeivS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binarizing the results\n",
        "\n",
        "We can convert the outputs of linear regression to a 0/1 classification by setting a threshold separating what we consider to be zero-predictions and what we consider to be one-predictions. In this case, it makes sense why a threshold to 0.49 gives an accuracy of near 100%."
      ],
      "metadata": {
        "id": "r7Qjvu1ZipR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "threshold = 0.49 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "binary_predictions = np.digitize(predictions, [threshold])\n",
        "\n",
        "print(f\"Using threshold: {threshold:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, binary_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_labels, binary_predictions))"
      ],
      "metadata": {
        "id": "xYMGjV83hh8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Using logistic regression\n",
        "\n",
        "Logistic regression directly models this as a classification problem so it should perform at least the same or better than linear regression with a threshold.\n",
        "\n",
        "In this specific example, both approaches are likely to perform similarly, because the data is linearly separable with clear boundaries."
      ],
      "metadata": {
        "id": "KjuZwGYUll4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = make_pipeline(\n",
        "    # Reshape 2D images into a 1D array of pixel values\n",
        "    reshape,\n",
        "    # Normalize the values to have comparable magnitude for\n",
        "    # better performance and faster convergence\n",
        "    StandardScaler(),\n",
        "    # Run training through logistic regression\n",
        "    LogisticRegression(penalty='l2', C=0.01))\n",
        "\n",
        "# Run the training\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "print(predictions)\n",
        "print(test_labels)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels, predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_labels, predictions))"
      ],
      "metadata": {
        "id": "oLvf5CBjCLJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Exercise 2: Classify the full dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "EYrX7NtQmf54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Attempting a linear regression\n",
        "\n",
        "Again, we can try using linear regression with thresholds to bucket the model's output in 10 different buckets for 10 different digits.\n",
        "\n",
        "The model does typically output values around the digit. However, the thresholds no longer do a good enough job of neatly separating predictions, because the shapes overlap quite a bit more. It's harder to distinguish between 6 and 7 than it is to distinguish between a simple circle (0) and a simple line (1)."
      ],
      "metadata": {
        "id": "RkDzRM_vn1k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(\n",
        "    # Reshape 2D images into a 1D array of pixel values\n",
        "    reshape,\n",
        "    # Normalize the values to have comparable magnitude for\n",
        "    # better performance and faster convergence\n",
        "    StandardScaler(),\n",
        "    # Run training through linear regression\n",
        "    LinearRegression())\n",
        "\n",
        "# Run the model\n",
        "model.fit(xtrain, ytrain)\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(xtest)\n",
        "\n",
        "print(predictions)\n",
        "print(ytest)\n",
        "\n",
        "thresholds = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
        "predicted_classes = np.digitize(predictions, thresholds)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(ytest, predicted_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(ytest, predicted_classes))\n"
      ],
      "metadata": {
        "id": "ikhlstwwmzWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Using a one-versus-rest approach\n",
        "\n",
        "Instead of manually setting thresholds to bucket the predictions of a linear regression model, we could use a one-versus-rest approach to train 10 models, one for each digit.\n",
        "\n",
        "This gives a much better accuracy than linear regression.\n"
      ],
      "metadata": {
        "id": "fKcq3J8O7mFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "model = OneVsRestClassifier(\n",
        "    make_pipeline(\n",
        "      # Reshape 2D images into a 1D array of pixel values\n",
        "      reshape,\n",
        "      # Normalize the values to have comparable magnitude for\n",
        "      # better performance and faster convergence\n",
        "      StandardScaler(),\n",
        "      # Run training for each individual model\n",
        "      LogisticRegression(max_iter=2000)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Run the model\n",
        "model.fit(xtrain, ytrain)\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(xtest)\n",
        "\n",
        "print(predictions)\n",
        "print(ytest)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(ytest, predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(ytest, predictions))\n"
      ],
      "metadata": {
        "id": "SEFXVvcu7r-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Multiclass approach"
      ],
      "metadata": {
        "id": "iVQVj-Cx83-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(\n",
        "      # Reshape 2D images into a 1D array of pixel values\n",
        "      reshape,\n",
        "      # Normalize the values to have comparable magnitude for\n",
        "      # better performance and faster convergence\n",
        "      StandardScaler(),\n",
        "      # Run training through linear regression\n",
        "      # Here, multinomial is already inferred\n",
        "      LogisticRegression(max_iter=2000)\n",
        "    )\n",
        "\n",
        "# Run the model\n",
        "model.fit(xtrain, ytrain)\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(xtest)\n",
        "\n",
        "print(predictions)\n",
        "print(ytest)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(ytest, predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(ytest, predictions))"
      ],
      "metadata": {
        "id": "AKFFjF4j86Kd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}